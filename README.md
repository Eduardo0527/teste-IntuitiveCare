# Teste TÃ©cnico - IntuitiveCare

Este repositÃ³rio contÃ©m a soluÃ§Ã£o completa para o desafio tÃ©cnico da IntuitiveCare. O projeto abrange o ciclo completo de engenharia de dados e desenvolvimento, desde a extraÃ§Ã£o (Web Scraping/ETL), tratamento e validaÃ§Ã£o, modelagem de banco de dados (SQL) atÃ© a exposiÃ§Ã£o dos dados via API e Interface Web.

---

## ğŸ›  Tecnologias Utilizadas

- **Linguagem:** Python 3
- **AnÃ¡lise de Dados:** Pandas
- **Banco de Dados:** MySQL
- **Backend:** Flask (Python)
- **Frontend:** HTML5 + Vue.js (CDN)
- **Bibliotecas:** `requests`, `beautifulsoup4`, `sqlalchemy`, `pymysql`, `flask-cors`.

---

## ğŸš€ Parte 1: ExtraÃ§Ã£o e TransformaÃ§Ã£o (ETL)

### ğŸ“¥ EstratÃ©gia de ExtraÃ§Ã£o
O enunciado menciona que o CSV consolidado deveria conter colunas como `CNPJ` e `RazaoSocial`, porÃ©m os arquivos fonte (anos/trimestres) possuem apenas `REG_ANS` e `CD_CONTA_CONTABIL`. AlÃ©m disso, devido Ã  indisponibilidade da API REST mencionada no teste, optou-se por uma abordagem de **Web Scraping**.

**Processamento:**
O processamento foi realizado utilizando DataFrames em memÃ³ria, iterando trimestre por trimestre e consolidando apenas ao final.

> **Trade-off TÃ©cnico (Item 1.2)**
>
> * **DecisÃ£o:** Processamento independente de cada trimestre, adicionando a uma lista `all_data` e consolidando no final.
> * **Justificativa:** Como o escopo abrange apenas 3 trimestres de dados tabulares, o volume cabe na memÃ³ria de um PC moderno (alguns GBs). O carregamento total simultÃ¢neo estouraria a RAM se fossem muitos anos.
> * **OtimizaÃ§Ã£o:** Utilizei `io.BytesIO` para baixar o ZIP diretamente na RAM e extrair sem salvar em disco previamente, otimizando a performance dado que I/O de disco Ã© geralmente o gargalo. Se fosse um histÃ³rico de 10 anos, a opÃ§Ã£o seria *stream* linha a linha para o disco.

### âš ï¸ Tratamento de InconsistÃªncias (Item 1.3)

* **CNPJ Duplicado:** O cÃ³digo detecta se um mesmo CNPJ possui nomes diferentes (comum em mudanÃ§as de RazÃ£o Social). A decisÃ£o crÃ­tica foi **padronizar pelo primeiro nome encontrado**.
* **Valores MonetÃ¡rios:** ConversÃ£o da formataÃ§Ã£o brasileira (`1.000,00`) para `float` Python. Zeros foram removidos (irrelevantes), mas **valores negativos foram mantidos**, pois representam estornos contÃ¡beis vÃ¡lidos.

---

## ğŸ”„ Parte 2: Enriquecimento e ValidaÃ§Ã£o

Devido Ã  ausÃªncia de CNPJs nos arquivos financeiros originais, a ordem das tarefas foi invertida: primeiro baixa-se a base cadastral para enriquecimento, cruza-se os dados e, por fim, valida-se.

### EstratÃ©gia de Cruzamento (Join)

> **DecisÃ£o de Chave:** **Registro ANS (`REGISTRO_OPERADORA`)**
> * **Motivo:** O arquivo de despesas possuÃ­a o cÃ³digo da operadora confiÃ¡vel. O Registro ANS Ã© a chave imutÃ¡vel no ecossistema da agÃªncia, enquanto CNPJs podem mudar (reestruturaÃ§Ã£o societÃ¡ria, matriz/filial), tornando o Registro ANS mais robusto.

> **Trade-off no JOIN (Tarefa 2.2)**
> * **DecisÃ£o:** `how='left'` join (Tabela de Despesas Ã  esquerda).
> * **Justificativa:** O foco Ã© o volume financeiro. Operadoras que tiveram despesas no passado mas foram liquidadas (nÃ£o constam no arquivo de "Ativas" atual) devem ser contabilizadas. Um `inner join` perderia esse histÃ³rico. Dados cadastrais faltantes foram marcados como "N/D".

### âœ… ValidaÃ§Ã£o de CNPJ (Tarefa 2.1)

ImplementaÃ§Ã£o do algoritmo oficial da Receita Federal (cÃ¡lculo de dÃ­gitos verificadores baseados em pesos e resto da divisÃ£o).

> **Trade-off na ValidaÃ§Ã£o**
> * **DecisÃ£o:** Registros com CNPJs invÃ¡lidos ou nÃ£o encontrados **NÃƒO** foram excluÃ­dos. Criou-se uma flag `CNPJ_Valido` (True/False).
> * **Justificativa:** Em auditoria, um dado invÃ¡lido Ã© um *finding* (achado), nÃ£o lixo. Excluir a linha esconderia milhÃµes em despesas ocorridas sob cadastros problemÃ¡ticos. O dado Ã© mantido e marcado para filtragem analÃ­tica posterior.

### ğŸ“Š AgregaÃ§Ã£o (Tarefa 2.3)

UtilizaÃ§Ã£o do `groupby` do Pandas por `RazaoSocial` e `UF`.
* **Desafio Adicional:** CÃ¡lculo de MÃ©dia e Desvio PadrÃ£o realizado em duas etapas (Soma por trimestre -> Agrupamento por operadora para `mean` e `std`) para identificar a estabilidade ou volatilidade dos gastos.

---

## ğŸ—„ï¸ Parte 3: Banco de Dados e SQL

### Arquitetura e Modelagem

> **Trade-off: NormalizaÃ§Ã£o**
> * **Escolha:** **OpÃ§Ã£o B - Tabelas Normalizadas Separadas.**
> * **Justificativa:**
>     1.  **OrganizaÃ§Ã£o:** Evita repetir RazÃ£o Social, CNPJ e EndereÃ§o em cada linha de despesa (economia de espaÃ§o e integridade).
>     2.  **Performance:** As somas sÃ£o feitas em uma tabela de fatos "magra" (apenas IDs numÃ©ricos e valores), o que Ã© mais performÃ¡tico.

### Tipos de Dados
* **Dinheiro:** `DECIMAL(15, 2)`. *Motivo:* `FLOAT` Ã© aproximado; `DECIMAL` Ã© exato (financeiro). Perder centavos em contabilidade Ã© inaceitÃ¡vel.
* **Datas:** `DATE`. *Motivo:* Garante ordenaÃ§Ã£o cronolÃ³gica correta, ao contrÃ¡rio de `VARCHAR`.

### Queries AnalÃ­ticas Desenvolvidas

1.  **Top 5 Crescimento de Despesas:** `(Valor Final - Valor Inicial) / Valor Inicial`. Filtra apenas empresas com dados presentes em ambas as pontas.
2.  **DistribuiÃ§Ã£o por UF:** Uso de `GROUP BY` por estado com cÃ¡lculo de mÃ©dia por operadora dentro do agrupamento.
3.  **Operadoras com Despesas Consistentemente Altas (Query 3):**
    * *EstratÃ©gia:* `CROSS JOIN` com subquery de mÃ©dia escalar.
    * *Justificativa TÃ©cnica:* Optou-se por **`COUNT(DISTINCT d.trimestre)`** ao invÃ©s de `COUNT` simples. Isso garante a precisÃ£o mesmo se houver duplicaÃ§Ã£o de dados na ingestÃ£o, assegurando que um mesmo trimestre nÃ£o seja contabilizado mÃºltiplas vezes.

---

## ğŸŒ Parte 4: API e Interface Web

### Backend (Flask)

> **Escolha do Framework: Flask (OpÃ§Ã£o A)**
>
> "Optei pelo Flask devido Ã  sua simplicidade e maturidade. Enquanto o FastAPI oferece melhor performance assÃ­ncrona, o Flask Ã© robusto e perfeitamente capaz de lidar com o volume de dados do teste sem a complexidade adicional de tipagem estÃ¡tica. A facilidade de integraÃ§Ã£o com SQLAlchemy foi decisiva."

### DecisÃµes de Arquitetura da API
1.  **PaginaÃ§Ã£o:** **Offset-based (OpÃ§Ã£o A)**. ImplementaÃ§Ã£o simples (`LIMIT x OFFSET y`). Para o volume atual, nÃ£o hÃ¡ degradaÃ§Ã£o de performance que justifique Cursor-based.
2.  **Cache vs Queries Diretas:** **Queries Diretas (OpÃ§Ã£o A)**. Os dados da ANS sÃ£o atualizados trimestralmente. Redis seria *over-engineering* para dados estÃ¡ticos; MySQL responde em milissegundos.
3.  **Busca:** **Servidor (OpÃ§Ã£o A)** via SQL (`LIKE %...%`). Filtrar no client-side consumiria banda excessiva e sobrecarregaria o navegador.

---

## â–¶ï¸ Como Executar o Projeto

Siga a ordem abaixo para reproduzir a soluÃ§Ã£o completa:

### 1. ExtraÃ§Ã£o (Parte 1)
Execute o script de scraping para baixar e consolidar os dados brutos.
```bash
python scraping.py
```

### 2. ValidaÃ§Ã£o e Enriquecimento (Parte 2)

Execute o script de validaÃ§Ã£o para baixar os dados cadastrais, cruzar com as despesas e gerar os relatÃ³rios.

```bash
python validacao.py
```

## 3. Banco de Dados (Parte 3)

### A. CriaÃ§Ã£o da Estrutura
Execute o script `criar_banco.sql` no seu cliente MySQL (Workbench, DBeaver, ou via terminal).
* Isso criarÃ¡ o banco de dados `teste_ans` e as tabelas necessÃ¡rias.

### B. ImportaÃ§Ã£o dos Dados
1. Edite o arquivo `importar_banco.py`.
2. Troque o valor do campo `SENHA_MYSQL` pela sua senha do banco de dados.
3. Execute o script:

```bash
python importar_banco.py
```
### C. AnÃ¡lise SQL
Execute as queries contidas no arquivo `queries.sql` no seu cliente MySQL para visualizar os resultados das perguntas de negÃ³cio.

---

## 4. Servidor e Frontend (Parte 4)

### A. ConfiguraÃ§Ã£o da API
1. Edite o arquivo `api.py`.
2. Troque o valor do campo `SENHA_MYSQL` pela sua senha do banco de dados.

### B. Iniciar Servidor
Execute o script abaixo para subir a API:

```bash
python api.py
```
> Aguarde a mensagem no terminal confirmando que o servidor estÃ¡ rodando na porta `5000`.

### C. Acessar Interface
VÃ¡ atÃ© a pasta do projeto e dÃª um duplo clique no arquivo `index.html` para abrir o Dashboard no seu navegador.